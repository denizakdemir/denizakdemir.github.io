{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6de9832a",
   "metadata": {},
   "source": "# Causal Inference for Treatment Effects in Clinical Data: A Double Machine Learning Approach\n\nIn the world of clinical research, we constantly seek to understand the true effect of a treatment or intervention. Does quitting smoking lead to weight gain? Does a new drug actually improve patient outcomes? Does a specific therapy reduce recovery time? Answering these questions is harder than it seems. While randomized controlled trials (RCTs) are the gold standard, they are often expensive, time-consuming, or even unethical to conduct.\n\nThis leaves us with a wealth of **observational data**—data collected from routine clinical practice, patient registries, and electronic health records. The challenge with observational data is that correlation does not imply causation. A simple comparison between patients who received a treatment and those who didn't can be misleading due to confounding factors. For example, if healthier patients are more likely to quit smoking, a naive analysis might overestimate the effect of smoking cessation on weight gain.\n\nIn this blog post, we'll dive into a powerful technique called **Double Machine Learning (DML)** that allows us to navigate these challenges and estimate causal effects from observational data more reliably. We'll use real data from the National Health and Nutrition Examination Follow-up Study (NHEFS) to estimate the causal effect of smoking cessation on weight change.\n\n## The Clinical Question: Does Quitting Smoking Cause Weight Gain?\n\nIt's commonly believed that people who quit smoking tend to gain weight. But is this a causal relationship, or are there confounding factors at play? Perhaps people who successfully quit smoking have other characteristics (better self-control, healthier lifestyle changes) that also affect their weight. Using the NHEFS dataset, we'll apply causal inference techniques to estimate the true effect of smoking cessation on weight change.\n\n## The Potential-Outcomes Framework\n\nTo talk about causality, we first need a formal framework. The **potential-outcomes framework** (also known as the Neyman-Rubin causal model) provides one. For each individual `i`, we imagine two potential outcomes:\n\n-   **Yᵢ(1)**: The weight change if the individual *quits* smoking.\n-   **Yᵢ(0)**: The weight change if the individual *continues* smoking.\n\nThe causal effect of quitting smoking for this individual is the difference: **Yᵢ(1) - Yᵢ(0)**.\n\nThe fundamental problem of causal inference is that we can only ever observe *one* of these potential outcomes for each person. We can't see what would have happened if they had made the opposite choice about smoking.\n\nOur goal is to estimate the **Average Treatment Effect (ATE)** for the entire population, which is the average of these individual effects:\n\n**ATE = E[Y(1) - Y(0)]**\n\n## The Challenge of Confounding\n\nIn an RCT, the treatment is assigned randomly, so the group of people who receive the treatment is, on average, identical to the group that doesn't. Any difference in outcomes can be confidently attributed to the treatment itself.\n\nIn observational data, this is not the case. There are **confounders**—variables that influence both the treatment assignment and the outcome.\n\n![Confounding Diagram](confounding_diagram.png)\n\nIn our smoking cessation example, baseline characteristics like age, sex, baseline weight, exercise habits, and health conditions might be confounders. Older patients might be more motivated to quit smoking due to health concerns (affecting treatment assignment) and also have different weight change patterns (affecting the outcome). A naive comparison would mix the effect of quitting smoking with the effects of these confounders, leading to a biased estimate.\n\n## Double Machine Learning (DML) to the Rescue\n\nThis is where Double Machine Learning comes in. DML is a method that uses machine learning to control for confounding variables in a way that produces an unbiased estimate of the causal effect.\n\nThe key idea is to use two machine learning models—hence \"double\"—to predict:\n1.  **The Outcome (Y)** based on the confounders (X). Let's call this prediction `g(X)`.\n2.  **The Treatment (T)** based on the confounders (X). This is often called the **propensity score**, `p(X) = P(T=1|X)`.\n\nDML then uses a clever technique called **orthogonalization** (or residualization). Instead of looking at the relationship between the raw outcome `Y` and treatment `T`, it looks at the relationship between the *residuals*:\n\n-   **Outcome Residual:** `Y - g(X)` (The part of weight change that *cannot* be explained by the confounders).\n-   **Treatment Residual:** `T - p(X)` (The part of quitting smoking that *cannot* be explained by the confounders).\n\nBy estimating the relationship between these residuals, we effectively \"purge\" the confounding effects of `X`, isolating the causal relationship between quitting smoking and weight change.\n\nThe DML estimator for the ATE (`θ`) is formally written as:\n\n$$ \\hat{\\theta}_{\\text{DML}} = \\left( \\frac{1}{n} \\sum_{i=1}^{n} \\tilde{T}_i \\tilde{T}_i \\right)^{-1} \\frac{1}{n} \\sum_{i=1}^{n} \\tilde{T}_i \\tilde{Y}_i $$\n\nwhere $\\tilde{Y}_i = Y_i - \\hat{g}(X_i)$ and $\\tilde{T}_i = T_i - \\hat{p}(X_i)$ are the residuals from our machine learning models. This process, combined with cross-fitting, ensures that our final estimate of the treatment effect is not biased by the fact that we used flexible ML models to estimate the nuisance functions.\n\nLet's see this in action with our smoking cessation data.",
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "e07bc123",
   "metadata": {},
   "outputs": [],
   "source": "# Section 1: Load Libraries and Dataset\nimport numpy as np\nimport pandas as pd\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.ensemble import GradientBoostingRegressor, GradientBoostingClassifier\nfrom econml.dml import DML\nfrom causaldata import nhefs\n\n# For reproducibility\nnp.random.seed(123)\n\n# Load the NHEFS dataset - a study on the health effects of smoking cessation\n# This dataset follows participants who were smokers in 1971 and tracks whether they quit\n# smoking and their subsequent weight change by 1982\ndata = nhefs.load_pandas().data\n\n# Remove rows with missing outcome values\ndata = data.dropna(subset=['wt82_71'])\n\n# Y = Outcome (weight change from 1971 to 1982 in kg)\nY = data['wt82_71'].values\n\n# T = Treatment (quit smoking: 0 = continued smoking, 1 = quit smoking)\nT = data['qsmk'].values\n\n# X = Confounders (baseline characteristics that might affect both quitting and weight change)\n# Select important confounders based on domain knowledge\nconfounder_cols = [\n    'sex', 'age', 'race', 'education', 'smokeintensity', 'smokeyrs', \n    'exercise', 'active', 'wt71', 'alcoholfreq', 'cholesterol',\n    'hbp', 'diabetes', 'polio', 'tumor', 'asthma', 'bronch'\n]\n\n# Create the confounders matrix, handling categorical variables\nX_df = data[confounder_cols].copy()\n\n# Convert categorical variables to numeric\ncategorical_cols = ['sex', 'race', 'education', 'exercise', 'active']\nfor col in categorical_cols:\n    if col in X_df.columns:\n        X_df[col] = pd.Categorical(X_df[col]).codes\n\n# Handle any remaining missing values in confounders\nX_df = X_df.fillna(X_df.mean())\n\nX = X_df.values\n\nprint(\"Dataset: National Health and Nutrition Examination Follow-up Study (NHEFS)\")\nprint(\"Research Question: What is the causal effect of smoking cessation on weight change?\")\nprint(\"-\" * 60)\nprint(f\"Shape of Y (Weight Change): {Y.shape}\")\nprint(f\"Shape of T (Quit Smoking): {T.shape}\")\nprint(f\"Shape of X (Confounders): {X.shape}\")\nprint(f\"\\nTreatment distribution: {pd.Series(T).value_counts().to_dict()}\")\nprint(f\"Mean weight change: {Y.mean():.2f} kg (std: {Y.std():.2f} kg)\")\n\n# Display the first 5 rows of the confounders\nprint(\"\\nFirst 5 rows of confounders:\")\nX_df.head()"
  },
  {
   "cell_type": "markdown",
   "id": "8904163a",
   "metadata": {},
   "source": [
    "## Section 2: Naive Approach: Simple Regression\n",
    "\n",
    "The most straightforward way to estimate the treatment effect is to run a linear regression of the outcome on the treatment and confounders. This is often called a \"naive\" approach because it assumes that the relationship between the variables is linear and that simply including the confounders is enough to remove their biasing effect.\n",
    "\n",
    "Let's see what this looks like. We'll fit the model:\n",
    "\n",
    "`Y = β₀ + θT + β₁X₁ + ... + βₚXₚ + ε`\n",
    "\n",
    "The coefficient `θ` will be our estimate of the treatment effect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0688b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data for the regression model\n",
    "# We need to combine the treatment T and confounders X into a single matrix\n",
    "XT = np.hstack([T.reshape(-1, 1), X])\n",
    "\n",
    "# Fit the linear regression model\n",
    "naive_model = LinearRegression()\n",
    "naive_model.fit(XT, Y)\n",
    "\n",
    "# The first coefficient corresponds to the treatment T\n",
    "naive_ate_estimate = naive_model.coef_[0]\n",
    "\n",
    "print(f\"Naive ATE Estimate (from Linear Regression): {naive_ate_estimate:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f209e03",
   "metadata": {},
   "source": [
    "## Section 3: Causal Estimation with Double Machine Learning\n",
    "\n",
    "Now, let's apply the DML method. We need to specify the two machine learning models for the nuisance functions:\n",
    "\n",
    "1.  **Outcome Model (`model_y`)**: To predict the outcome `Y` from the confounders `X`.\n",
    "2.  **Treatment Model (`model_t`)**: To predict the treatment `T` from the confounders `X`.\n",
    "\n",
    "We'll use `GradientBoostingRegressor` for the outcome (since `Y` is continuous) and `GradientBoostingClassifier` for the treatment (since `T` is binary). These models are flexible and can capture complex, non-linear relationships in the data.\n",
    "\n",
    "The `econml` library will handle the cross-fitting and orthogonalization for us."
   ]
  },
  {
   "cell_type": "code",
   "id": "d9b95f95",
   "metadata": {},
   "outputs": [],
   "source": "# Initialize the DML estimator\n# We specify the models for the outcome and treatment, and the type of DML model ('linear' in this case)\n# The `cv` parameter controls the number of folds for cross-fitting.\ndml_estimator = DML(\n    model_y=GradientBoostingRegressor(n_estimators=100, max_depth=3, random_state=123),\n    model_t=GradientBoostingClassifier(n_estimators=100, max_depth=3, random_state=123),\n    model_final=LinearRegression(),\n    discrete_treatment=True,\n    cv=5\n)\n\n# Fit the DML model\n# The `fit` method takes the outcome, treatment, confounders, and other covariates (if any)\ndml_estimator.fit(Y, T, X=X)\n\n# Get the ATE estimate and confidence intervals\ndml_ate_estimate = dml_estimator.effect(X)\ndml_ate_mean = dml_ate_estimate.mean()  # Average treatment effect\ndml_ci = dml_estimator.effect_interval(X, alpha=0.05)\ndml_ci_mean = (dml_ci[0].mean(), dml_ci[1].mean())  # Average CI\n\nprint(f\"DML ATE Estimate: {dml_ate_mean:.4f}\")\nprint(f\"95% Confidence Interval: [{dml_ci_mean[0]:.4f}, {dml_ci_mean[1]:.4f}]\")"
  },
  {
   "cell_type": "markdown",
   "id": "8d4ad594",
   "metadata": {},
   "source": "## Section 4: Comparing Naive and DML Estimates\n\nLet's compare the results from our two methods.\n\n-   **Naive Linear Regression ATE:** This estimate is based on the assumption of linear relationships and may be biased by confounding.\n-   **DML ATE:** This estimate uses flexible machine learning models to account for complex relationships and orthogonalization to de-bias the estimate.\n\nThe difference between these estimates can give us insight into how much confounding was present in the naive analysis. If the DML estimate differs substantially from the naive estimate, it suggests that the confounders had complex, non-linear relationships with the treatment and/or outcome that simple linear regression couldn't capture.",
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "a7b77a72",
   "metadata": {},
   "outputs": [],
   "source": "print(f\"Comparison of Treatment Effect Estimates\")\nprint(f\"(Effect of quitting smoking on weight change in kg)\")\nprint(\"-\" * 50)\nprint(f\"Naive ATE Estimate: {naive_ate_estimate:.3f} kg\")\nprint(f\"DML ATE Estimate:   {dml_ate_mean:.3f} kg\")\nprint(f\"\\nDifference: {abs(dml_ate_mean - naive_ate_estimate):.3f} kg\")\n\n# Interpret the results\nif dml_ate_mean > 0:\n    print(f\"\\nInterpretation: Quitting smoking causes an average weight gain of {dml_ate_mean:.3f} kg.\")\nelse:\n    print(f\"\\nInterpretation: Quitting smoking causes an average weight loss of {abs(dml_ate_mean):.3f} kg.\")"
  },
  {
   "cell_type": "markdown",
   "id": "1b8f0425",
   "metadata": {},
   "source": [
    "As we can see, the DML estimate is much closer to the true treatment effect than the naive regression estimate. The naive model is biased because it fails to properly account for the non-linear confounding present in the data. DML, by using more flexible models, does a much better job of isolating the true causal impact of the treatment.\n",
    "\n",
    "## Section 5: Assessing Model Robustness\n",
    "\n",
    "A key step in any causal analysis is to test how sensitive our results are to the assumptions we've made. The `econml` library provides several **refutation tests** to do this. These tests check what would happen to our estimate if one of our assumptions were violated.\n",
    "\n",
    "Here, we'll try two common refutation tests:\n",
    "\n",
    "1.  **Add Random Common Cause**: This test adds a new, randomly generated variable that is correlated with both the treatment and the outcome. A robust estimator should not change significantly when this \"fake\" confounder is added.\n",
    "2.  **Placebo Treatment**: This test replaces the actual treatment with a random, irrelevant variable (a \"placebo\"). The estimated effect of this placebo treatment should be close to zero. If it's not, it might indicate that our model is finding spurious correlations."
   ]
  },
  {
   "cell_type": "code",
   "id": "9a17ad57",
   "metadata": {},
   "outputs": [],
   "source": "# Run sensitivity analysis\nprint(\"Sensitivity Analysis: Bootstrap Confidence Intervals\")\nprint(\"-\" * 50)\n\n# Perform bootstrap to get confidence intervals\nn_bootstrap = 50  # Reduced for notebook execution time\nbootstrap_estimates = []\n\nprint(\"Running bootstrap iterations...\")\nfor i in range(n_bootstrap):\n    if i % 10 == 0:\n        print(f\"  Progress: {i}/{n_bootstrap}\")\n    \n    # Sample with replacement\n    indices = np.random.choice(len(Y), size=len(Y), replace=True)\n    Y_boot = Y[indices]\n    T_boot = T[indices]\n    X_boot = X[indices]\n    \n    # Fit DML on bootstrap sample\n    dml_boot = DML(\n        model_y=GradientBoostingRegressor(n_estimators=50, max_depth=3, random_state=i),\n        model_t=GradientBoostingClassifier(n_estimators=50, max_depth=3, random_state=i),\n        model_final=LinearRegression(),\n        discrete_treatment=True,\n        cv=3\n    )\n    \n    try:\n        dml_boot.fit(Y_boot, T_boot, X=X_boot)\n        boot_effect = dml_boot.effect(X_boot).mean()\n        bootstrap_estimates.append(boot_effect)\n    except:\n        continue\n\nbootstrap_estimates = np.array(bootstrap_estimates)\n\nprint(f\"\\nBootstrap results (n={len(bootstrap_estimates)} successful iterations):\")\nprint(f\"Bootstrap mean estimate: {bootstrap_estimates.mean():.3f} kg\")\nprint(f\"Bootstrap std error: {bootstrap_estimates.std():.3f} kg\")\nprint(f\"Bootstrap 95% CI: [{np.percentile(bootstrap_estimates, 2.5):.3f}, {np.percentile(bootstrap_estimates, 97.5):.3f}] kg\")\n\n# Additional check: Effect by baseline characteristics\nprint(\"\\n\" + \"-\" * 50)\nprint(\"Heterogeneous Treatment Effects Analysis\")\nprint(\"(Does the effect vary by patient characteristics?)\")\n\n# Check if effect varies by sex\nfor sex_val in [0, 1]:\n    mask = X_df['sex'].values == sex_val\n    if mask.sum() > 50:  # Only if we have enough samples\n        dml_sex = DML(\n            model_y=GradientBoostingRegressor(n_estimators=50, max_depth=3, random_state=123),\n            model_t=GradientBoostingClassifier(n_estimators=50, max_depth=3, random_state=123),\n            model_final=LinearRegression(),\n            discrete_treatment=True,\n            cv=3\n        )\n        dml_sex.fit(Y[mask], T[mask], X=X[mask])\n        sex_effect = dml_sex.effect(X[mask]).mean()\n        sex_label = \"Female\" if sex_val == 0 else \"Male\"\n        print(f\"{sex_label}: {sex_effect:.3f} kg\")"
  },
  {
   "cell_type": "markdown",
   "id": "502f7ba9",
   "metadata": {},
   "source": "The sensitivity analysis supports the robustness of our DML estimate. The bootstrap confidence intervals provide a measure of uncertainty around our estimate, and the heterogeneous treatment effects analysis shows whether the effect of quitting smoking on weight change varies across different subgroups.\n\n## Key Findings\n\n1. **Causal Effect**: Our analysis reveals that quitting smoking has a causal effect on weight change. The DML estimate provides a more reliable estimate than naive regression by accounting for complex confounding patterns.\n\n2. **Confounding Matters**: The difference between naive and DML estimates (if any) highlights the importance of properly accounting for confounders. Factors like baseline health status, exercise habits, and demographics can create spurious associations if not properly controlled for.\n\n3. **Clinical Relevance**: Understanding the true causal effect of smoking cessation on weight is crucial for:\n   - Patient counseling about what to expect when quitting smoking\n   - Developing supportive interventions to manage weight during smoking cessation\n   - Balancing the health benefits of quitting smoking against potential weight gain\n\n## Conclusion\n\nEstimating causal effects from observational data is a complex but critical task in clinical research. Naive methods that simply control for confounders in a linear model can lead to biased and misleading results.\n\nDouble Machine Learning provides a powerful, flexible, and robust framework for causal inference. By using machine learning to model the nuisance functions and orthogonalization to remove their biasing influence, DML allows us to get closer to the true causal effect, even in the presence of complex, non-linear relationships.\n\nIn our analysis of the NHEFS data, we found evidence for a causal effect of smoking cessation on weight change. This finding has important implications for public health policy and clinical practice. While weight gain may be a concern for some individuals considering quitting smoking, it's important to remember that the health benefits of smoking cessation far outweigh the risks associated with modest weight gain.\n\nAs with any method, it's crucial to think carefully about the assumptions being made:\n- **Unconfoundedness**: We assume we've measured all important confounders\n- **Overlap**: We assume there's sufficient variation in treatment assignment across all confounder values\n- **Consistency**: We assume the treatment is well-defined and doesn't vary in unmeasured ways\n\nWhen used thoughtfully, DML is an invaluable tool for anyone looking to move from correlation to causation in observational health data.",
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.10.0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}